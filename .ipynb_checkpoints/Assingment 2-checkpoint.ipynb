{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import *\n",
    "#from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENVIRONMENT"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This is the environment declaration, as well as other functions that are used in it and the agent.\n",
    "\n",
    "It is important to note that both of the agents can work in the same environment.\n",
    "\n",
    "The environment is called \"Grid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaration of gold and trap things to be used in the environment.\n",
    "class Gold(Thing): \n",
    "    pass\n",
    "\n",
    "class Trap(Thing):\n",
    "    pass\n",
    "#Useful functions made during development.\n",
    "def isTheCellInTheList(cellList,a): #Checks if a location is in a given list.\n",
    "    for x in cellList:\n",
    "        if x == a:\n",
    "            return True\n",
    "    return False  \n",
    "    \n",
    "def canIaddTheCell(cellList,a): #Checks if a cell is in a given list, if so it returns false.\n",
    "    for x in cellList:\n",
    "        if x == a:\n",
    "            return False\n",
    "    return True\n",
    "  \n",
    "def chevyshev(loc1,loc2): #Gives the chevyshev distance between two locations\n",
    "    return max(abs(loc1[0]-loc2[0]),abs(loc1[1]-loc2[1]))\n",
    "\n",
    "def finishedExploring(visibleList): #checks if the list includes all the possible values in the grid\n",
    "    for x in range(0,5):\n",
    "        for y in range(0,5): \n",
    "            if isTheCellInTheList(visibleList,[x,y]) == False:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def getUnexploredCell(visibleList): #searches for a location (cell) that is not in the list and returns it\n",
    "    for x in range(0,5):\n",
    "        for y in range(0,5): \n",
    "            if isTheCellInTheList(visibleList,[x,y]) == False:\n",
    "                print(str([x,y]))\n",
    "                return [x,y]\n",
    "\n",
    "def onedge(ap): #checks if a given cell goes beyond the grid\n",
    "    if (ap[0] >= 5 or ap[1] >= 5 or ap[1] <= -1 or ap[0] <= -1):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def manhattan(loc1,loc2): #returns the manhattan distance between two cells\n",
    "    return abs(loc1[0]-loc2[0])+abs(loc1[1]-loc2[1])\n",
    "\n",
    "def getgoal(perps,p): #returns the closest cell with gold\n",
    "    closestdistance = 99\n",
    "    for k in perps:\n",
    "        if isinstance(k[0], Gold):\n",
    "            if closestdistance == 99 or (manhattan(p[1],k[1]) <= closestdistance):\n",
    "                closestdistance = manhattan(p[1],k[1])\n",
    "                goal = k[1]\n",
    "            #print(\"current closest distance = \"+str(goal))\n",
    "    return goal\n",
    "\n",
    "def getgoalanddist(perps,p): #returns the closest cell with gold and the distance to it\n",
    "    closestdistance = 99\n",
    "    for k in perps:\n",
    "        if isinstance(k[0], Gold):\n",
    "            if closestdistance == 99 or (manhattan(p[1],k[1]) <= closestdistance):\n",
    "                closestdistance = manhattan(p[1],k[1])\n",
    "                goal = k[1]\n",
    "            #print(\"current closest distance = \"+str(goal))\n",
    "    return goal,closestdistance\n",
    "\n",
    "\n",
    "def amITrapped(perps,p): #checks if the agent p is in the same cell as a Trap\n",
    "    for k in perps:\n",
    "        if isinstance(k[0], Trap):\n",
    "            if (manhattan(p[1],k[1]) == 0):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def getadvanceposition(p): #gets the next position of the agent p in regards to the direction.\n",
    "    if p[0].direction==\"right\":\n",
    "        return [p[1][0],p[1][1]+1]\n",
    "    elif p[0].direction == \"left\":\n",
    "        return [p[1][0],p[1][1]-1]\n",
    "    elif p[0].direction == \"up\":\n",
    "        return [p[1][0]-1,p[1][1]]\n",
    "    elif p[0].direction == \"down\":\n",
    "        return [p[1][0]+1,p[1][1]]\n",
    "    \n",
    "    \n",
    "    \n",
    "def istheregold(perps): #searches all of the percepts in order to attain if there is gold left in the environment\n",
    "    for p in perps:\n",
    "        if isinstance(p[0],Gold):\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "def printNormalEnvironment(agent,grid): #prints the environment without things like visited cells, showing the full grid with the agent direction.\n",
    "    for x in range(0,5):\n",
    "        for y in range(0,5):\n",
    "            if(agent.location == [x,y]):\n",
    "                if(agent.direction == \"right\"):\n",
    "                    charhero = 'R'\n",
    "                elif(agent.direction == \"left\"):\n",
    "                    charhero = 'L'\n",
    "                elif(agent.direction == \"up\"):\n",
    "                    charhero = 'U'\n",
    "                elif(agent.direction == \"down\"):\n",
    "                    charhero = \"D\"\n",
    "            else:\n",
    "                charhero = '-'\n",
    "            thingsgold = grid.list_things_at([x,y], tclass=Gold)\n",
    "            thingstrap = grid.list_things_at([x,y],tclass=Trap)\n",
    "            if len(thingsgold) != 0 or len(thingstrap) != 0:\n",
    "                if(len(thingsgold) == 0):\n",
    "                    chargold = \"-\"\n",
    "                else:\n",
    "                    chargold = str(len(thingsgold))\n",
    "                if(len(thingstrap) == 0):\n",
    "                    chartrap = \"-\"\n",
    "                else: \n",
    "                    chartrap = str(len(thingstrap))\n",
    "                print(\"(\"+charhero+\",\"+chargold+\",\"+chartrap+\") \", end = '')\n",
    "            else:\n",
    "                print(\"(\"+charhero+\",-,-) \", end = '')\n",
    "        print(\"\\n\")\n",
    "        \n",
    "\n",
    "def printAgentPercept(agent,grid): #prints just the cells that the limited agent can see, those with a chevishev distance of <= 1\n",
    "    for x in range(0,5):\n",
    "        for y in range(0,5):\n",
    "            if(chevyshev(agent.location,[x,y])<=1):\n",
    "                if(agent.location == [x,y]):\n",
    "                    if(agent.direction == \"right\"):\n",
    "                        charhero = 'R'\n",
    "                    elif(agent.direction == \"left\"):\n",
    "                        charhero = 'L'\n",
    "                    elif(agent.direction == \"up\"):\n",
    "                        charhero = 'U'\n",
    "                    elif(agent.direction == \"down\"):\n",
    "                        charhero = \"D\"\n",
    "                else:\n",
    "                    charhero = '-'\n",
    "\n",
    "                thingsgold = grid.list_things_at([x,y], tclass=Gold)\n",
    "                thingstrap = grid.list_things_at([x,y],tclass=Trap)\n",
    "                if len(thingsgold) != 0 or len(thingstrap) != 0:\n",
    "                    if(len(thingsgold) == 0):\n",
    "                        chargold = \"-\"\n",
    "                    else:\n",
    "                        chargold = str(len(thingsgold))\n",
    "                    if(len(thingstrap) == 0):\n",
    "                        chartrap = \"-\"\n",
    "                    else: \n",
    "                        chartrap = str(len(thingstrap))\n",
    "                    print(\"(\"+charhero+\",\"+chargold+\",\"+chartrap+\") \", end = '')\n",
    "                else:\n",
    "                    print(\"(\"+charhero+\",-,-) \", end = '')\n",
    "        print(\"\\n\")     \n",
    "        \n",
    "def printAgentMemory(agent,grid): #prints the cells that the agent has memory of or can see at the moment, the rest are labeled as question marks (unknown)\n",
    "    for x in range(0,5):\n",
    "        for y in range(0,5):\n",
    "            if(not isTheCellInTheList(agent.visibleList,[x,y])):\n",
    "                print(\"(?,?,?) \", end = '')\n",
    "            else:\n",
    "                if(isTheCellInTheList(agent.visitedList,[x,y])):\n",
    "                    charhero = 'V'\n",
    "                else:\n",
    "                    charhero = '-'\n",
    "                thingsgold = grid.list_things_at([x,y], tclass=Gold)\n",
    "                thingstrap = grid.list_things_at([x,y],tclass=Trap)\n",
    "                if len(thingsgold) != 0 or len(thingstrap) != 0:\n",
    "                    if(len(thingsgold) == 0):\n",
    "                        chargold = \"-\"\n",
    "                    else:\n",
    "                        chargold = str(len(thingsgold))\n",
    "                    if(len(thingstrap) == 0):\n",
    "                        chartrap = \"-\"\n",
    "                    else: \n",
    "                        chartrap = str(len(thingstrap))\n",
    "                    print(\"(\"+charhero+\",\"+chargold+\",\"+chartrap+\") \", end = '')\n",
    "                else:\n",
    "                    print(\"(\"+charhero+\",-,-) \", end = '')\n",
    "        print(\"\\n\")     \n",
    "        \n",
    "def printUnknownEnvironment(agent,grid): #Similar to \"printNormalEnvironment\". However, it prints the visited cells and forgoes the agent direction and position, opting to go for representation as a visited cell\n",
    "    for x in range(0,5):\n",
    "        for y in range(0,5):\n",
    "            if(isTheCellInTheList(agent.visitedList,[x,y])):\n",
    "                charhero = 'V'\n",
    "            else:\n",
    "                charhero = '-'\n",
    "            thingsgold = grid.list_things_at([x,y], tclass=Gold)\n",
    "            thingstrap = grid.list_things_at([x,y],tclass=Trap)\n",
    "            if len(thingsgold) != 0 or len(thingstrap) != 0:\n",
    "                if(len(thingsgold) == 0):\n",
    "                    chargold = \"-\"\n",
    "                else:\n",
    "                    chargold = str(len(thingsgold))\n",
    "                if(len(thingstrap) == 0):\n",
    "                    chartrap = \"-\"\n",
    "                else: \n",
    "                    chartrap = str(len(thingstrap))\n",
    "                print(\"(\"+charhero+\",\"+chargold+\",\"+chartrap+\") \", end = '')\n",
    "            else:\n",
    "                print(\"(\"+charhero+\",-,-) \", end = '')\n",
    "        print(\"\\n\")    \n",
    "\n",
    "class Grid(Environment): #Declaration of environment\n",
    "    def percept(self, agent):\n",
    "        things = []\n",
    "        '''Returns the full list of things in the environment, this is useful for both agents, note that it returns the agent AND their location, for easier handling'''\n",
    "        for x in range(0,5):\n",
    "            for y in range(0,5):\n",
    "                if(len(self.list_things_at([x,y]))!= 0):\n",
    "                    for thing in self.list_things_at([x,y]):                        \n",
    "                        things.append([thing,[x,y]])        \n",
    "        #print(things)\n",
    "        return things\n",
    "    def execute_action(self, agent, action): \n",
    "        '''Called when executing an action, this first displays the environment before the action takes place'''\n",
    "        print(\"START\")\n",
    "        print(\"Format: (A G T)\")\n",
    "        print(\"Environment previous to action\") #Important graphical cues\n",
    "        if isinstance(agent,blindHero): #If the agent is \"blind\"(limited visibility) it displays the corresponding information, else it displays the grid environment as it is.\n",
    "            printUnknownEnvironment(agent,self)\n",
    "            print(\"Agent Percepts\")\n",
    "            printAgentPercept(agent,self)\n",
    "            print(\"Internal state of agent\")\n",
    "            printAgentMemory(agent,self)\n",
    "        else: \n",
    "            printNormalEnvironment(agent,self)\n",
    "            \n",
    "        print(\"Agent performance: \"+str(agent.points)) #Display of points before the action has taken place.\n",
    "        \n",
    "        print(\"Action to be taken: \")\n",
    "        \n",
    "        '''changes the state of the environment based on what the agent does.'''\n",
    "        if action == \"advance\": #advance action, in case there are things in the environment after advancing(when the agent enters a cell), it applies the \"advance and get affected action\", which means that the agent will change position and get affected by the first trap and gold in the cell. It also gets rid of the object once the action has taken place. \n",
    "            itemsGold = self.list_things_at(getadvanceposition([agent,agent.location]), tclass=Gold)\n",
    "            itemsTraps = self.list_things_at(getadvanceposition([agent,agent.location]), tclass=Trap)\n",
    "            if len(itemsGold) == 0 and len(itemsTraps) == 0:\n",
    "                agent.advance()\n",
    "            elif len(itemsGold) != 0 and len(itemsTraps) == 0:\n",
    "                if agent.advanceAndGetAffected([itemsGold[0]]):\n",
    "                    self.delete_thing(itemsGold[0])                   \n",
    "            elif len(itemsGold) == 0 and len(itemsTraps) != 0:\n",
    "                if agent.advanceAndGetAffected([itemsTraps[0]]):\n",
    "                    self.delete_thing(itemsTraps[0])                    \n",
    "            else:\n",
    "                if agent.advanceAndGetAffected([itemsGold[0],itemsTraps[0]]): \n",
    "                    self.delete_thing(itemsGold[0])\n",
    "                    self.delete_thing(itemsTraps[0])\n",
    "        elif action == \"turn\": #Turn action, the same logic applies in which if there are objects in the cell they will affect the agent.\n",
    "            itemsGold = self.list_things_at(agent.location, tclass=Gold)\n",
    "            itemsTraps = self.list_things_at(agent.location, tclass=Trap)\n",
    "            if len(itemsGold) == 0 and len(itemsTraps) == 0:\n",
    "                agent.turn()\n",
    "            elif len(itemsGold) != 0 and len(itemsTraps) == 0:\n",
    "                if agent.turnAndGetAffected([itemsGold[0]]):\n",
    "                    self.delete_thing(itemsGold[0])                   \n",
    "            elif len(itemsGold) == 0 and len(itemsTraps) != 0:\n",
    "                if agent.turnAndGetAffected([itemsTraps[0]]):\n",
    "                    self.delete_thing(itemsTraps[0])                    \n",
    "            else:\n",
    "                if agent.turnAndGetAffected([itemsGold[0],itemsTraps[0]]):\n",
    "                    self.delete_thing(itemsGold[0])\n",
    "                    self.delete_thing(itemsTraps[0])                     \n",
    "        elif action == \"stay\": #Stay action, as the other two actions it retains the action variation in case of elements in the cell\n",
    "            itemsGold = self.list_things_at(agent.location, tclass=Gold)\n",
    "            itemsTraps = self.list_things_at(agent.location, tclass=Trap)\n",
    "            if len(itemsGold) == 0 and len(itemsTraps) == 0:\n",
    "                agent.stay()\n",
    "            elif len(itemsGold) != 0 and len(itemsTraps) == 0:\n",
    "                if agent.stayAndGetAffected([itemsGold[0]]):\n",
    "                    self.delete_thing(itemsGold[0])                   \n",
    "            elif len(itemsGold) == 0 and len(itemsTraps) != 0:\n",
    "                if agent.stayAndGetAffected([itemsTraps[0]]):\n",
    "                    self.delete_thing(itemsTraps[0])                    \n",
    "            else:\n",
    "                if agent.stayAndGetAffected([itemsGold[0],itemsTraps[0]]):\n",
    "                    self.delete_thing(itemsGold[0])\n",
    "                    self.delete_thing(itemsTraps[0])    \n",
    "        '''Displays the environment after it has been affected by the agent's actions'''\n",
    "        print(\"Environment after action\")\n",
    "        if isinstance(agent,blindHero):\n",
    "            printUnknownEnvironment(agent,self)\n",
    "            print(\"Agent Percepts\")\n",
    "            printAgentPercept(agent,self)\n",
    "            print(\"Internal state of agent\")\n",
    "            printAgentMemory(agent,self)\n",
    "        else:\n",
    "            printNormalEnvironment(agent,self)\n",
    "        print(\"Agent performance: \"+str(agent.points)) #Displays new score for the agent\n",
    "        print(\"---------------------------------------------------------------------------------------\") #Separator line for better visibility\n",
    "        print(\"\\n\")\n",
    "            \n",
    "            \n",
    "    def add_thing(self, thing, location=None): #Declaration of add_thing function, currently redundant\n",
    "        \"\"\"Add a thing to the environment, setting its location. For\n",
    "        convenience, if thing is an agent program we make a new agent\n",
    "        for it. (Shouldn't need to override this.\"\"\"\n",
    "        if not isinstance(thing, Thing):\n",
    "            thing = Agent(thing)\n",
    "        assert thing not in self.things, \"Don't add the same thing twice\"\n",
    "        thing.location = location if location is not None else self.default_location(thing)\n",
    "        self.things.append(thing)\n",
    "        if isinstance(thing, Agent):\n",
    "            thing.performance = 0\n",
    "            self.agents.append(thing)\n",
    "    \n",
    "    def is_done(self): #If there are no living agents the environment stops\n",
    "        dead_agents = not any(agent.is_alive() for agent in self.agents)\n",
    "        return dead_agents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AGENT DECLARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first Agent, the agent name is \"Hero\" and it has 100 points assigned, starting by default in the \"right\" position. It is capable of perceiving the complete environment and takes actions accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Hero(Agent):\n",
    "    location = [1,1]\n",
    "    points = 100\n",
    "    direction = \"right\"\n",
    "    \n",
    "    def advance(self): #Advance action just modifies it's location with respect to its direction\n",
    "        print(\"ADVANCE\")\n",
    "        if(self.direction == \"right\"):\n",
    "            self.location[1]+=1\n",
    "        elif(self.direction == \"left\"):\n",
    "            self.location[1]-=1\n",
    "        elif(self.direction== \"up\"):\n",
    "            self.location[0] -=1\n",
    "        elif(self.direction== \"down\"):\n",
    "            self.location[0] += 1\n",
    "        self.points -= 1\n",
    "    def advanceAndGetAffected(self,lista): #advance and get affected sums or substracts points from the agent regarding the list of objects obtained from the environment\n",
    "        print(\"ADVANCE\")\n",
    "        if(self.direction == \"right\"):\n",
    "            self.location[1]+=1\n",
    "        elif(self.direction == \"left\"):\n",
    "            self.location[1]-=1\n",
    "        elif(self.direction== \"up\"):\n",
    "            self.location[0] -=1\n",
    "        elif(self.direction== \"down\"):\n",
    "            self.location[0] += 1\n",
    "        self.points -= 1\n",
    "        for x in lista:\n",
    "            if isinstance(x,Gold):\n",
    "                self.points += 10\n",
    "            if isinstance(x,Trap):\n",
    "                self.points -= 5\n",
    "        return True\n",
    "    def turn(self): #turn changes the direction of the agent\n",
    "        print(\"TURN\")\n",
    "        if(self.direction == \"right\"):\n",
    "            self.direction = \"down\"\n",
    "        elif(self.direction == \"left\"):\n",
    "            self.direction = \"up\"\n",
    "        elif(self.direction== \"up\"):\n",
    "            self.direction =\"right\"\n",
    "        elif(self.direction== \"down\"):\n",
    "            self.direction = \"left\"\n",
    "        self.points -= 1\n",
    "    def turnAndGetAffected(self,lista): #same logic applies as \"advance and get affected\"\n",
    "        print(\"TURN\")\n",
    "        if(self.direction == \"right\"):\n",
    "            self.direction = \"down\"\n",
    "        elif(self.direction == \"left\"):\n",
    "            self.direction = \"up\"\n",
    "        elif(self.direction== \"up\"):\n",
    "            self.direction =\"right\"\n",
    "        elif(self.direction== \"down\"):\n",
    "            self.direction = \"left\"\n",
    "        self.points -= 1\n",
    "        for x in lista:\n",
    "            if isinstance(x,Gold):\n",
    "                self.points += 10\n",
    "            if isinstance(x,Trap):\n",
    "                self.points -= 5\n",
    "        return True\n",
    "    def stay(self): #doesn't do anything, except print the action\n",
    "        print(\"STAY\")\n",
    "    def stayAndGetAffected(self,lista): #it modifies the agent score with respect to the objects in the environment\n",
    "        print(\"STAY\")\n",
    "        for x in lista:\n",
    "            if isinstance(x,Gold):\n",
    "                self.points += 10\n",
    "            if isinstance(x,Trap):\n",
    "                self.points -= 5\n",
    "        return True        \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def program2(percepts): \n",
    "    '''Program for the first agent (who can see all the environment)'''\n",
    "    if istheregold(percepts) == False: #if there's no more gold there's no reason to do anything, therefore it returns stay by default\n",
    "        return 'stay'\n",
    "    else:\n",
    "        for p in percepts:\n",
    "            if isinstance(p[0], Hero): #finds the agent first, with the information from it, it can take different actions\n",
    "                goal = getgoalanddist(percepts,p) #gets closest gold piece\n",
    "                ap = getadvanceposition(p) #Next position in current trajectory\n",
    "                #print(\"My goal is: \"+str(goal[0])+\" and my next move is: \"+str(ap))\n",
    "                if onedge(ap): #if it's on the edge it returns \"turn\", if there is gold it will still get affected and it won't be punished for leaving the grid\n",
    "                    return 'turn'\n",
    "                else:\n",
    "                    if manhattan(goal[0],ap) < goal[1]: #it checks if the distance to the goal is reduced by advancing, if so it takes a step\n",
    "                        return 'advance'\n",
    "                    elif manhattan(goal[0],p[1]) == 0: #if the agent is in the same place as the gold piece it stays\n",
    "                        return 'stay'\n",
    "                    elif amITrapped(percepts,p): #if the agent is in a trap and no other option is favorable it takes a step to try to avoid it\n",
    "                        return 'advance'\n",
    "                    else: #if it doesn't know what to do or the step doesn't reduce distance it turns to try another direction.\n",
    "                        return 'turn'\n",
    "    return 'advance' #redundant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the declaration of the second agent. The name is \"blind Hero\", as he can only see so far. This agent has different characteristics, such as a visited cells List and visible cells List. The first records the places where the agent has been and the second records the places the agent can currently see or has seen in the past; these are visible since the environment doesn't change and, therefore, if the agent has seen it, it knows exactly what is in the cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class blindHero(Agent): #Blind Hero agent\n",
    "    location = [3,3]\n",
    "    points = 100\n",
    "    direction = \"right\"\n",
    "    visitedList = [] #list of visited cells\n",
    "    visibleList = [] #list of visible Cells\n",
    "    def advance(self):\n",
    "        print(\"ADVANCE\") #advance action, identical to the first agent's, with the exception that if the new cell has been visited it substracts points from the agent \n",
    "        if(self.direction == \"right\"):\n",
    "            self.location[1]+=1\n",
    "        elif(self.direction == \"left\"):\n",
    "            self.location[1]-=1\n",
    "        elif(self.direction== \"up\"):\n",
    "            self.location[0] -=1\n",
    "        elif(self.direction== \"down\"):\n",
    "            self.location[0] += 1\n",
    "        self.points -= 1\n",
    "        if (isTheCellInTheList(self.visitedList,self.location)): #this was done since we thought that the potential reward of exploring the environment could offset the risks of moving freely, therefore no \"avoidance\" of the visited cells was coded\n",
    "            self.points -= 2\n",
    "    def advanceAndGetAffected(self,lista): #Identical to first agent's advanceAndGetAffected action.\n",
    "        print(\"ADVANCE\")\n",
    "        if(self.direction == \"right\"):\n",
    "            self.location[1]+=1\n",
    "        elif(self.direction == \"left\"):\n",
    "            self.location[1]-=1\n",
    "        elif(self.direction== \"up\"):\n",
    "            self.location[0] -=1\n",
    "        elif(self.direction== \"down\"):\n",
    "            self.location[0] += 1\n",
    "        self.points -= 1\n",
    "        for x in lista:\n",
    "            if isinstance(x,Gold):\n",
    "                self.points += 10\n",
    "            if isinstance(x,Trap):\n",
    "                self.points -= 5\n",
    "        return True\n",
    "    def turn(self):\n",
    "        print(\"TURN\") #turn action \n",
    "        if(self.direction == \"right\"):\n",
    "            self.direction = \"down\"\n",
    "        elif(self.direction == \"left\"):\n",
    "            self.direction = \"up\"\n",
    "        elif(self.direction== \"up\"):\n",
    "            self.direction =\"right\"\n",
    "        elif(self.direction== \"down\"):\n",
    "            self.direction = \"left\"\n",
    "        self.points -= 1\n",
    "    def turnAndGetAffected(self,lista): #turn and get affected action\n",
    "        print(\"TURN\")\n",
    "        if(self.direction == \"right\"):\n",
    "            self.direction = \"down\"\n",
    "        elif(self.direction == \"left\"):\n",
    "            self.direction = \"up\"\n",
    "        elif(self.direction== \"up\"):\n",
    "            self.direction =\"right\"\n",
    "        elif(self.direction== \"down\"):\n",
    "            self.direction = \"left\"\n",
    "        self.points -= 1\n",
    "        for x in lista:\n",
    "            if isinstance(x,Gold):\n",
    "                self.points += 10\n",
    "            if isinstance(x,Trap):\n",
    "                self.points -= 5\n",
    "        return True\n",
    "    def stay(self):\n",
    "        print(\"STAY\")\n",
    "    def stayAndGetAffected(self,lista):\n",
    "        print(\"STAY\")\n",
    "        for x in lista:\n",
    "            if isinstance(x,Gold):\n",
    "                self.points += 10\n",
    "            if isinstance(x,Trap):\n",
    "                self.points -= 5\n",
    "        return True        \n",
    "    #Since the action that is dependent of visited cells is only \"advance\" there was no need for further modification to the actions of the agent\n",
    "                        \n",
    "\n",
    "def program3(percepts):\n",
    "    '''Program used for blind hero'''\n",
    "    temporalpercepts = [] #list of percepts of the agent, since we get back a full list of objects it was important to create a subset of percepts regarding the agent's memory and visibility\n",
    "    goal = [] #goal (closest gold piece)\n",
    "    unexp = [] #closest unexplored cell\n",
    "    for p in percepts:\n",
    "        if isinstance(p[0], blindHero): #find the agent\n",
    "            p[0].visitedList.append(p[1]) #add the current cell to the visited list\n",
    "            for x in range(0,5): #checks all the cells and if there are new cells which the agent couldn't see before, it adds them to the visible list\n",
    "                for y in range(0,5): \n",
    "                    if chevyshev([x,y],p[0].location) <= 1:\n",
    "                        if canIaddTheCell(p[0].visibleList,[x,y]):\n",
    "                            p[0].visibleList.append([x,y])\n",
    "            for k in percepts: #checks the position of all the objects, adding them to the current percepts if they are visible to the agent\n",
    "                if isTheCellInTheList(p[0].visibleList,k[1]):\n",
    "                    temporalpercepts.append(k)\n",
    "            #print(temporalpercepts)\n",
    "            if istheregold(temporalpercepts) == False: #if there is no more gold perceived and all the cells have been explored, it returns \"stay\" indefinitely since there's no reason to move.\n",
    "                if finishedExploring(p[0].visibleList):\n",
    "                    return 'stay'\n",
    "                else: #if not all the places have been explored, it goes on to explore, treating the unexp variable as the \"goal\" in the first agent\n",
    "                    unexp = getUnexploredCell(p[0].visibleList)\n",
    "                    ap = getadvanceposition(p) #Next position in current trajectory\n",
    "                    if onedge(ap):\n",
    "                        return 'turn'\n",
    "                    else:\n",
    "                        if manhattan(unexp,ap) < manhattan(unexp,p[0].location):\n",
    "                            return 'advance'\n",
    "                        elif manhattan(unexp,p[1]) == 0:\n",
    "                            return 'stay'\n",
    "                        elif amITrapped(temporalpercepts,p):\n",
    "                            return 'advance'\n",
    "                        else: \n",
    "                            return 'turn'\n",
    "            else: #if there's still gold perceived it acts in the same way as the first agent\n",
    "                goal = getgoalanddist(temporalpercepts,p) #Closest gold piece or unexplored cell\n",
    "                ap = getadvanceposition(p) #Next position in current trajectory\n",
    "                if onedge(ap):\n",
    "                    return 'turn'\n",
    "                else:\n",
    "                    if manhattan(goal[0],ap) < goal[1]:\n",
    "                        return 'advance'\n",
    "                    elif manhattan(goal[0],p[1]) == 0:\n",
    "                        return 'stay'\n",
    "                    elif amITrapped(temporalpercepts,p):\n",
    "                        return 'advance'\n",
    "                    else: \n",
    "                        return 'turn'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(R,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 100\n",
      "Action to be taken: \n",
      "STAY\n",
      "Environment after action\n",
      "(R,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 110\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(R,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 110\n",
      "Action to be taken: \n",
      "TURN\n",
      "Environment after action\n",
      "(D,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 109\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(D,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 109\n",
      "Action to be taken: \n",
      "ADVANCE\n",
      "Environment after action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(D,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 108\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(D,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 108\n",
      "Action to be taken: \n",
      "ADVANCE\n",
      "Environment after action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(D,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 107\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(D,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 107\n",
      "Action to be taken: \n",
      "ADVANCE\n",
      "Environment after action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(D,-,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 116\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(D,-,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 116\n",
      "Action to be taken: \n",
      "ADVANCE\n",
      "Environment after action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(D,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 115\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(D,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 115\n",
      "Action to be taken: \n",
      "TURN\n",
      "Environment after action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(L,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 114\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(L,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 114\n",
      "Action to be taken: \n",
      "TURN\n",
      "Environment after action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(U,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 113\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(U,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 113\n",
      "Action to be taken: \n",
      "TURN\n",
      "Environment after action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(R,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 112\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(R,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 112\n",
      "Action to be taken: \n",
      "ADVANCE\n",
      "Environment after action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (R,1,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 121\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (R,1,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 121\n",
      "Action to be taken: \n",
      "STAY\n",
      "Environment after action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (R,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 131\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (R,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 131\n",
      "Action to be taken: \n",
      "ADVANCE\n",
      "Environment after action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (R,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 130\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (R,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 130\n",
      "Action to be taken: \n",
      "ADVANCE\n",
      "Environment after action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (R,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 129\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (R,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 129\n",
      "Action to be taken: \n",
      "TURN\n",
      "Environment after action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (D,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 128\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (D,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 128\n",
      "Action to be taken: \n",
      "TURN\n",
      "Environment after action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (L,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 127\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (L,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 127\n",
      "Action to be taken: \n",
      "TURN\n",
      "Environment after action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (U,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 126\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (U,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 126\n",
      "Action to be taken: \n",
      "ADVANCE\n",
      "Environment after action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (U,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 130\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (U,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 130\n",
      "Action to be taken: \n",
      "ADVANCE\n",
      "Environment after action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (U,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 129\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (U,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 129\n",
      "Action to be taken: \n",
      "ADVANCE\n",
      "Environment after action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (U,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 123\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (U,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 123\n",
      "Action to be taken: \n",
      "ADVANCE\n",
      "Environment after action\n",
      "(-,-,-) (-,-,-) (-,-,-) (U,-,-) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 117\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,-,-) (-,-,-) (-,-,-) (U,-,-) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 117\n",
      "Action to be taken: \n",
      "TURN\n",
      "Environment after action\n",
      "(-,-,-) (-,-,-) (-,-,-) (R,-,-) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 116\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,-,-) (-,-,-) (-,-,-) (R,-,-) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 116\n",
      "Action to be taken: \n",
      "ADVANCE\n",
      "Environment after action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (R,-,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 125\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (R,-,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 125\n",
      "Action to be taken: \n",
      "STAY\n",
      "Environment after action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (R,-,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 125\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid = Grid()\n",
    "hero = Hero(program2)\n",
    "goldpiece = Gold()\n",
    "goldpiece2 = Gold()\n",
    "goldpiece3 = Gold()\n",
    "goldpiece4 = Gold()\n",
    "goldpiece5 = Gold()\n",
    "goldpiece6 = Gold()\n",
    "trap1 = Trap()\n",
    "trap2 = Trap()\n",
    "trap = Trap()\n",
    "trap4 = Trap()\n",
    "trap3 = Trap()\n",
    "grid.add_thing(hero, [0,0])\n",
    "grid.add_thing(goldpiece, [4,1])\n",
    "grid.add_thing(trap, [3,3])\n",
    "grid.add_thing(goldpiece2, [4,1])\n",
    "grid.add_thing(goldpiece5, [0,0])\n",
    "grid.add_thing(goldpiece6, [0,4])\n",
    "grid.add_thing(goldpiece4, [3,0])\n",
    "grid.add_thing(goldpiece3, [3,3])\n",
    "grid.add_thing(trap1, [1,1])\n",
    "grid.add_thing(trap2, [1,1])\n",
    "grid.add_thing(trap3, [0,3])\n",
    "grid.add_thing(trap4, [1,3])\n",
    "grid.run(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "(-,-,2) (-,-,-) (-,-,1) \n",
      "\n",
      "(-,-,-) (U,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,1,1) \n",
      "\n",
      "\n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,-) (V,-,-) (-,-,-) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,-) (-,-,-) (-,1,1) (?,?,?) \n",
      "\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "Agent performance: 100\n",
      "Action to be taken: \n",
      "TURN\n",
      "Environment after action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "(-,-,2) (-,-,-) (-,-,1) \n",
      "\n",
      "(-,-,-) (R,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,1,1) \n",
      "\n",
      "\n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,-) (V,-,-) (-,-,-) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,-) (-,-,-) (-,1,1) (?,?,?) \n",
      "\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "Agent performance: 99\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "(-,-,2) (-,-,-) (-,-,1) \n",
      "\n",
      "(-,-,-) (R,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,1,1) \n",
      "\n",
      "\n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,-) (V,-,-) (-,-,-) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,-) (-,-,-) (-,1,1) (?,?,?) \n",
      "\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "Agent performance: 99\n",
      "Action to be taken: \n",
      "ADVANCE\n",
      "Environment after action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "(-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (R,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "\n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,-) (V,-,-) (-,-,-) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,-) (-,-,-) (-,1,1) (?,?,?) \n",
      "\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "Agent performance: 98\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "(-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (R,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "\n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(?,?,?) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(?,?,?) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "Agent performance: 98\n",
      "Action to be taken: \n",
      "TURN\n",
      "Environment after action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "(-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (D,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "\n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(?,?,?) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(?,?,?) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "Agent performance: 97\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "(-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (D,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "\n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(?,?,?) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(?,?,?) (-,-,-) (-,-,-) (-,1,1) (-,-,-) \n",
      "\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "Agent performance: 97\n",
      "Action to be taken: \n",
      "ADVANCE\n",
      "Environment after action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (D,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(?,?,?) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(?,?,?) (-,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "Agent performance: 101\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "[0, 0]\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (-,-,-) (-,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (D,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(?,?,?) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(?,?,?) (-,-,-) (-,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(?,?,?) (?,?,?) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 101\n",
      "Action to be taken: \n",
      "TURN\n",
      "Environment after action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (-,-,-) (-,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (L,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(?,?,?) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(?,?,?) (-,-,-) (-,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(?,?,?) (?,?,?) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 100\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "[0, 0]\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (-,-,-) (-,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (L,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(?,?,?) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(?,?,?) (-,-,-) (-,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(?,?,?) (?,?,?) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 100\n",
      "Action to be taken: \n",
      "ADVANCE\n",
      "Environment after action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (-,-,-) (-,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (L,-,-) (-,-,-) \n",
      "\n",
      "(-,2,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(?,?,?) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(?,?,?) (-,-,-) (-,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(?,?,?) (?,?,?) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 99\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (L,-,-) (-,-,-) \n",
      "\n",
      "(-,2,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(?,?,?) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(?,?,?) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(?,?,?) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 99\n",
      "Action to be taken: \n",
      "ADVANCE\n",
      "Environment after action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (L,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) \n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(?,?,?) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(?,?,?) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(?,?,?) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 98\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (L,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) \n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 98\n",
      "Action to be taken: \n",
      "TURN\n",
      "Environment after action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (U,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) \n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 97\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (U,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) \n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 97\n",
      "Action to be taken: \n",
      "TURN\n",
      "Environment after action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (R,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) \n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 96\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (R,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) \n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 96\n",
      "Action to be taken: \n",
      "TURN\n",
      "Environment after action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (D,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) \n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 95\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (D,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) \n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,2,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 95\n",
      "Action to be taken: \n",
      "ADVANCE\n",
      "Environment after action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,1,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(-,1,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (D,1,-) (-,-,-) \n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,1,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 104\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (V,1,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(-,1,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (D,1,-) (-,-,-) \n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (V,1,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 104\n",
      "Action to be taken: \n",
      "TURN\n",
      "Environment after action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(-,1,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (L,-,-) (-,-,-) \n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 113\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(-,1,-) (-,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (L,-,-) (-,-,-) \n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 113\n",
      "Action to be taken: \n",
      "ADVANCE\n",
      "Environment after action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(-,1,-) (-,-,-) \n",
      "\n",
      "(L,-,-) (-,-,-) \n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 112\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(-,1,-) (-,-,-) \n",
      "\n",
      "(L,-,-) (-,-,-) \n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 112\n",
      "Action to be taken: \n",
      "TURN\n",
      "Environment after action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(-,1,-) (-,-,-) \n",
      "\n",
      "(U,-,-) (-,-,-) \n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 111\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(-,1,-) (-,-,-) \n",
      "\n",
      "(U,-,-) (-,-,-) \n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,1,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 111\n",
      "Action to be taken: \n",
      "ADVANCE\n",
      "Environment after action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(-,-,-) (-,-,-) \n",
      "\n",
      "(U,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) \n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 120\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "[0, 0]\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(-,-,-) (-,-,-) \n",
      "\n",
      "(U,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) \n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 120\n",
      "Action to be taken: \n",
      "ADVANCE\n",
      "Environment after action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "(-,-,-) (-,-,2) \n",
      "\n",
      "(U,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) \n",
      "\n",
      "\n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(?,?,?) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(-,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 119\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "[0, 0]\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "\n",
      "\n",
      "(-,-,-) (-,-,2) \n",
      "\n",
      "(U,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,-) \n",
      "\n",
      "\n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 119\n",
      "Action to be taken: \n",
      "ADVANCE\n",
      "Environment after action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "(-,1,-) (-,-,-) \n",
      "\n",
      "(U,-,-) (-,-,2) \n",
      "\n",
      "(-,-,-) (-,-,-) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Internal state of agent\n",
      "(?,?,?) (?,?,?) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 118\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(-,1,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "(-,1,-) (-,-,-) \n",
      "\n",
      "(U,-,-) (-,-,2) \n",
      "\n",
      "(-,-,-) (-,-,-) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Internal state of agent\n",
      "(-,1,-) (-,-,-) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 118\n",
      "Action to be taken: \n",
      "ADVANCE\n",
      "Environment after action\n",
      "(-,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "(U,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,2) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Internal state of agent\n",
      "(-,-,-) (-,-,-) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 127\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "[0, 2]\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(V,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "(U,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,2) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Internal state of agent\n",
      "(V,-,-) (-,-,-) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 127\n",
      "Action to be taken: \n",
      "TURN\n",
      "Environment after action\n",
      "(V,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "(R,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,2) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Internal state of agent\n",
      "(V,-,-) (-,-,-) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 126\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "[0, 2]\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(V,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "(R,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,2) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Internal state of agent\n",
      "(V,-,-) (-,-,-) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 126\n",
      "Action to be taken: \n",
      "ADVANCE\n",
      "Environment after action\n",
      "(V,-,-) (-,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent Percepts\n",
      "(-,-,-) (R,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Internal state of agent\n",
      "(V,-,-) (-,-,-) (?,?,?) (?,?,?) (?,?,?) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 125\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "[0, 3]\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "(-,-,-) (R,-,-) (-,-,-) \n",
      "\n",
      "(-,-,-) (-,-,2) (-,-,-) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Internal state of agent\n",
      "(V,-,-) (V,-,-) (-,-,-) (?,?,?) (?,?,?) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 125\n",
      "Action to be taken: \n",
      "ADVANCE\n",
      "Environment after action\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "(-,-,-) (R,-,-) (-,-,1) \n",
      "\n",
      "(-,-,2) (-,-,-) (-,-,1) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Internal state of agent\n",
      "(V,-,-) (V,-,-) (-,-,-) (?,?,?) (?,?,?) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 124\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "[0, 4]\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(V,-,-) (V,-,-) (V,-,-) (-,-,1) (-,1,-) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "(-,-,-) (R,-,-) (-,-,1) \n",
      "\n",
      "(-,-,2) (-,-,-) (-,-,1) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Internal state of agent\n",
      "(V,-,-) (V,-,-) (V,-,-) (-,-,1) (?,?,?) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 124\n",
      "Action to be taken: \n",
      "ADVANCE\n",
      "Environment after action\n",
      "(V,-,-) (V,-,-) (V,-,-) (-,-,-) (-,1,-) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "(-,-,-) (R,-,-) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Internal state of agent\n",
      "(V,-,-) (V,-,-) (V,-,-) (-,-,-) (?,?,?) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 118\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,1,-) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "(-,-,-) (R,-,-) (-,1,-) \n",
      "\n",
      "(-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Internal state of agent\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,1,-) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 118\n",
      "Action to be taken: \n",
      "ADVANCE\n",
      "Environment after action\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "(-,-,-) (R,-,-) \n",
      "\n",
      "(-,-,1) (-,-,1) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Internal state of agent\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 127\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (V,-,-) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "(-,-,-) (R,-,-) \n",
      "\n",
      "(-,-,1) (-,-,1) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Internal state of agent\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (V,-,-) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 127\n",
      "Action to be taken: \n",
      "STAY\n",
      "Environment after action\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (V,-,-) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "(-,-,-) (R,-,-) \n",
      "\n",
      "(-,-,1) (-,-,1) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Internal state of agent\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (V,-,-) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 127\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "START\n",
      "Format: (A G T)\n",
      "Environment previous to action\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (V,-,-) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "(-,-,-) (R,-,-) \n",
      "\n",
      "(-,-,1) (-,-,1) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Internal state of agent\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (V,-,-) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 127\n",
      "Action to be taken: \n",
      "STAY\n",
      "Environment after action\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (V,-,-) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent Percepts\n",
      "(-,-,-) (R,-,-) \n",
      "\n",
      "(-,-,1) (-,-,1) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Internal state of agent\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (V,-,-) \n",
      "\n",
      "(V,-,-) (-,-,2) (-,-,-) (-,-,1) (-,-,1) \n",
      "\n",
      "(V,-,-) (-,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (V,-,-) (V,-,-) (-,-,-) \n",
      "\n",
      "(V,-,-) (V,-,-) (-,-,-) (-,-,-) (-,-,-) \n",
      "\n",
      "Agent performance: 127\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid2 = Grid()\n",
    "hero2 = blindHero(program3)\n",
    "hero2.direction = \"up\"\n",
    "goldpiece = Gold()\n",
    "goldpiece2 = Gold()\n",
    "goldpiece3 = Gold()\n",
    "goldpiece4 = Gold()\n",
    "goldpiece5 = Gold()\n",
    "goldpiece6 = Gold()\n",
    "trap1 = Trap()\n",
    "trap2 = Trap()\n",
    "trap = Trap()\n",
    "trap3 = Trap()\n",
    "trap4 = Trap()\n",
    "trap5 = Trap()\n",
    "grid2.add_thing(hero2, [2,2])\n",
    "grid2.add_thing(goldpiece, [0,0])\n",
    "grid2.add_thing(trap, [3,3])\n",
    "grid2.add_thing(goldpiece2, [3,0])\n",
    "grid2.add_thing(goldpiece5, [4,1])\n",
    "grid2.add_thing(goldpiece6, [4,1])\n",
    "grid2.add_thing(goldpiece4, [3,3])\n",
    "grid2.add_thing(goldpiece3, [0,4])\n",
    "grid2.add_thing(trap1, [1,1])\n",
    "grid2.add_thing(trap2, [1,1])\n",
    "grid2.add_thing(trap3, [1,4])\n",
    "grid2.add_thing(trap4, [0,3])\n",
    "grid2.add_thing(trap5, [1,3])\n",
    "grid2.run(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
